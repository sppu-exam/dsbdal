DATA ANALYTICS II  (PRACTICAL 5)

--------------------------------------------

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

------------------------------------------

df = pd.read_csv('Social_Network_Ads.csv')

------------------------------------------

print("----------------Dataframe Info------------------")
print(df.info())
print("\n")


-----------------------------------------

print("---------------Dataframe Descibe----------------")
print(df.describe())
print("\n")

-----------------------------------------

JST TO EXTEND CODE :_

print("---------------First 5 rows of Dataframe----------------")
print(df.head())
print("\n")


-----------------------------------------


print("---------------Train Dataset-------------")
X = df[['Age', 'EstimatedSalary']]
Y = df['Purchased']


------------------------------------------

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

---------------------------------------


X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)
print(f'Train Dataset Size - X: {X_train.shape}, Y: {Y_train.shape}')
print(f'Test  Dataset Size - X: {X_test.shape}, Y: {Y_test.shape}')

---------------------------------------------


print("----------------Linner Regression-------------------")
from sklearn.linear_model import LogisticRegression 

---------------------------------------------


lm = LogisticRegression(random_state=0, solver='lbfgs')
lm.fit(X_train, Y_train)
predictions = lm.predict(X_test)
plt.figure(figsize=(6, 6))
sns.regplot(x = X_test[:, 1], y = predictions, scatter_kws={'s':5})
plt.scatter(X_test[:, 1], Y_test, marker = '+')
plt.xlabel("User's Estimated Salary")
plt.ylabel('Ads Purchased')
plt.title('Regression Line Tracing')
plt.show()


------------------------------------------------


print("-------------Confusion Matrix---------------")
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

--------------------------------------------------------------------------------------------------------

cm = confusion_matrix(Y_test, predictions)
print(f'''Confusion matrix :\n
               | Positive Prediction\t| Negative Prediction
---------------+------------------------+----------------------
Positive Class | True Positive (TP) {cm[0, 0]}\t| False Negative (FN) {cm[0, 1]}
---------------+------------------------+----------------------
Negative Class | False Positive (FP) {cm[1, 0]}\t| True Negative (TN) {cm[1, 1]}\n\n''')


------------------------------------------------------------------------------------------------------------


cm = classification_report(Y_test, predictions)
print('Classification report : \n', cm)

------------------------------------------------------------------------
INFO:-

Visualizing Training set result
This code visualizes the training set results for the logistic regression model.
It creates a meshgrid of points, makes predictions on those points using the trained model,
and plots the decision boundary.
It also scatters the actual training data points, coloring them based on their true class.
This allows us to see how well the logistic regression model fits the training data.


--------------------------------------------------------------------------------------

print("-----------------Visualizing Training set result----------------")
from matplotlib.colors import ListedColormap
X_set, y_set = X_train, Y_train
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))


-----------------------------------------------------------------------------------
INFO:-

Visualizing Test set result
This code is visualizing the test set results after training the logistic regression model.
It creates meshgrid of points, makes predictions on those points using the trained model,
and plots the decision boundary. It also scatters the actual test set data points on top.
This allows us to visualize how well the model is able to separate the two classes on the test data.
The various plot settings like colors, alpha, labels etc help interpret the results better.


------------------------------------------------------------------------------------

print("-----------------Visualizing Test set result----------------")
from matplotlib.colors import ListedColormap
X_set, y_set = X_test, Y_test
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))



----------------------------------------------------------------------------------------










